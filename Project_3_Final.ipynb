{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tbfz3zSXBt3H"
      },
      "source": [
        "Created by: Joel Nail & Alex Yu\n",
        "\n",
        "# <p style=\"text-align: center;\">MIS 284N - Big Data and Distributed Programming</p>\n",
        "## <p style=\"text-align: center;\">Project 3 - Machine Learning using Tensorflow and Google Colab</p>\n",
        "## <p style=\"text-align: center;\">Total points: 100</p>\n",
        "## <p style=\"text-align: center;\">Due: Saturday, October 15th submitted via Canvas by 11:59 pm</p>\n",
        "\n",
        "This will be a in-class project done in teams of 2. \n",
        "\n",
        "In this Project, we will work with CIFAR10 image dataset. \n",
        "The starter code to download the database using keras is given below. \n",
        "Test the project on Google Colab running on a CPU, GPU and TPU\n",
        " \n",
        "\n",
        "# In every line of code, please write a comment to briefly explain what that line is doing.\n",
        "Your grades will be based on your understanding of the code you write! \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnHTzAuvxxQT"
      },
      "source": [
        "# Task 1\n",
        "Convert the features in a form that can be given as input to tensorflow library/functions\n",
        "\n",
        "In this task you will perform data augmentation. That is, pre-process the data to make the model more robust. Experiment with data augmentation techniques like rotation, translation, horizontal-flip, scaling, ZCA whitening and histogram equalization. \n",
        "You can choose any two or more augmentation technique(s) of your choice. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing necessary libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "import distutils\n",
        "if distutils.version.LooseVersion(tf.__version__) < '1.14':\n",
        "    raise Exception('This notebook is compatible with TensorFlow 1.14 or higher, for TensorFlow 1.13 or lower please use the previous version at https://github.com/tensorflow/tpu/blob/r1.13/tools/colab/fashion_mnist.ipynb')\n"
      ],
      "metadata": {
        "id": "X292oEZ32BA_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LQvjBuuyxblF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa7bd477-f278-4571-c54e-b9c121219788"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 3s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from keras.datasets import cifar10 # importing the cifar10 dataset\n",
        "import matplotlib.pyplot as plt # importing pyplot in order to display images and graphs\n",
        "import random # importing random in order to display random images\n",
        "%matplotlib inline # ensure that images and plots stay in the notebook\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data() # loading our train and test sets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Just a little test to see what the images look like**"
      ],
      "metadata": {
        "id": "tE0vxIr4kFmw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# selecting a random value between 0 and 100\n",
        "val = random.randint(0,100)\n",
        "# selecting a random image from the dataset to display\n",
        "image0 = x_train[val]\n",
        "# printing the shape of the image\n",
        "# print(image0.shape) \n",
        "\n",
        "plt.imshow(image0) # displaying the image\n",
        "print(int(y_train[val])) # printing the label of the image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "pUISNej125Sp",
        "outputId": "1919caa4-a4f3-44f6-cff6-57851f044704"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Performing data augmentation**"
      ],
      "metadata": {
        "id": "p9VMrCgRxirE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Big shoutout to Moritz Hambach's CIFAR GitHub project which provided me with \n",
        "# the inspiration for the following augmentation code\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# aug1: horizontal flip=True, rotation range=10\n",
        "# aug2: horizontal flip=True, rotation range=25\n",
        "# aug3: horizontal_flip=True, rotation_range=25, zca_whitening=True - NO GOOD\n",
        "\n",
        "# the below code defines ImageDataGenerator objects which will be used to augment our data\n",
        "# I have decided to implement several augmentation configurations to test multiple augmentation combinations\n",
        "\n",
        "dataAug1 = ImageDataGenerator(\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=10\n",
        ")\n",
        "\n",
        "# this was the best set of augmentations from my experiments\n",
        "# this image data generator will randomly apply the below augmentations to our dataset\n",
        "dataAug2 = ImageDataGenerator(\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=25,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1\n",
        ")\n",
        "\n",
        "# going all out here - didn't get great results from it\n",
        "dataAug3 = ImageDataGenerator(\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=25,\n",
        "    #zca_whitening=True,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1\n",
        ")\n",
        "\n",
        "dataAug2.fit(x_train) # fitting the model to our training set"
      ],
      "metadata": {
        "id": "6M6VX-hgkOEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualizing the transformations**"
      ],
      "metadata": {
        "id": "-Irh1jLLxfF6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# displaying the first image in the training set before augmentation\n",
        "image0 = x_train[0] # grabbing first image\n",
        "plt.imshow(image0) # displaying image\n",
        "plt.title(\"Non-Augmented\") # giving the image a title\n",
        "plt.show() # ensuring the image shows\n",
        "\n",
        "# displaying the first image in the training set after augmentation\n",
        "# i'm not sure why I had to put this in a for loop to get it to work\n",
        "# i think it is because the .flow method returns an iterator, but i'm not sure\n",
        "# turning shuffle to False so that we get the first image from the set\n",
        "for x_demo, y_demo in dataAug2.flow(x_train, y_train, batch_size=3, shuffle=False):\n",
        "  for i in range(0, 1):\n",
        "    plt.imshow(x_demo[i].astype(np.uint8)) # displaying the augmented image\n",
        "    plt.title(\"Augmented\") # giving the plot a title\n",
        "  plt.show() # ensuring the image shows\n",
        "  break # becase we only want to display the first image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "fxj0Qb85uDpa",
        "outputId": "e43adfa2-88dd-48d8-8abb-cb9d02b4889f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6c8xzloyoUD"
      },
      "source": [
        "# Task 2\n",
        "Build a Neural Network model, train on the features and report the accuracy.\n",
        "Report your observations on the time taken on CPU and GPU (with and without CuDNN kernel) \n",
        "\n",
        "\n",
        "\n",
        "1.   Create a CNN based model with 4 hidden layers with 64, 128, 256 and 512 units in each succesive layer. Use a 5x5 convolution kernel and change as necessary. (Use at least 2 augmentations on your input) \n",
        "2.   Create an LSTM based model with 1 LSTM layer with 256 units. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining Function to Create Model**"
      ],
      "metadata": {
        "id": "ICKvBM6Xi8pq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code to create model modified from Dr Y's FashionMNIST notebook\n",
        "def create_model():\n",
        "  model = tf.keras.models.Sequential() # we will be creating a sequential model with four layers\n",
        "  model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:])) # normalizing the inputs for the first layer\n",
        "  model.add(tf.keras.layers.Conv2D(64, (5, 5), padding='same', activation='elu')) # 2D convolution layer with 64 filters, a 5x5 kernel, padding, and ELU activation function\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2))) # performing max pooling to reduce number of features and prevent over-fitting\n",
        "  model.add(tf.keras.layers.Dropout(0.25)) # randomly setting inputs to 0 in effort to prevent overfitting\n",
        "\n",
        "  model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:])) # normalizing the inputs for the second layer\n",
        "  model.add(tf.keras.layers.Conv2D(128, (5, 5), padding='same', activation='elu')) # 2D convolution layer with 128 filters, a 5x5 kernel, padding, and ELU activation function\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2))) # performing max pooling to reduce number of features and prevent over-fitting\n",
        "  model.add(tf.keras.layers.Dropout(0.25)) # randomly setting inputs to 0 in effort to prevent overfitting\n",
        "\n",
        "  model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:])) # normalizing the inputs for the third layer\n",
        "  model.add(tf.keras.layers.Conv2D(256, (5, 5), padding='same', activation='elu')) # 2D convolution layer with 256 filters, a 5x5 kernel, padding, and ELU activation function\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2))) # performing max pooling to reduce number of features and prevent over-fitting\n",
        "  model.add(tf.keras.layers.Dropout(0.25)) # randomly setting inputs to 0 in effort to prevent overfitting\n",
        "\n",
        "  model.add(tf.keras.layers.BatchNormalization(input_shape=x_train.shape[1:])) # normalizing the inputs for the fourth layer\n",
        "  model.add(tf.keras.layers.Conv2D(512, (5, 5), padding='same', activation='elu')) # 2D convolution layer with 512 filters, a 5x5 kernel, padding, and ELU activation function\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2))) # performing max pooling to reduce number of features and prevent over-fitting\n",
        "  model.add(tf.keras.layers.Dropout(0.25)) # randomly setting inputs to 0 in effort to prevent overfitting\n",
        "\n",
        "  model.add(tf.keras.layers.Flatten()) # flattening input\n",
        "  model.add(tf.keras.layers.Dense(512)) # creating a densely connected layer with 512 units\n",
        "  model.add(tf.keras.layers.Activation('elu')) # using ELU activation function\n",
        "  model.add(tf.keras.layers.Dropout(0.5)) # randomly setting inputs to 0 in effort to prevent overfitting\n",
        "  model.add(tf.keras.layers.Dense(10)) # creating densely connected layer with 10 units (number of classes)\n",
        "  model.add(tf.keras.layers.Activation('softmax')) # using softmax activation function\n",
        "  return model"
      ],
      "metadata": {
        "id": "M6L0LcfC2EI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CNN Using CPU**"
      ],
      "metadata": {
        "id": "q_PQb4d-iJR-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelAug = create_model() # creating model to train on augmented data\n",
        "\n",
        "# compiling model with adam optimizer and sparse categorical crossentropy/accuracy as our evaluation metrics\n",
        "# learning rate of .001 is large enough that it doesn't take too long to run on CPU\n",
        "modelAug.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(learning_rate=.001),\n",
        "  loss='sparse_categorical_crossentropy',\n",
        "  metrics=['sparse_categorical_accuracy'])"
      ],
      "metadata": {
        "id": "xgF-EL8wzFW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "batch = 128 # chose batch size more or less randomly - seems to give good performance\n",
        "\n",
        "# steps per epoch was calculated as len(x_train)/batch_size\n",
        "\n",
        "# training model on augmented data with a batch size of 128 and 10 epochs with 391 steps per epoch\n",
        "historyAug = modelAug.fit(\n",
        "    dataAug2.flow(x_train, y_train, batch_size=batch), # this is where we perform our augmentation\n",
        "    epochs=10,\n",
        "    steps_per_epoch=391,\n",
        "    validation_data=(x_test.astype(np.float32), y_test.astype(np.float32)), # we'll use the test set to perform validation\n",
        "    validation_freq=1, # we want to validate using the test set on each epoch\n",
        "    batch_size = batch\n",
        ")\n",
        "\n",
        "# evaluating training set accuracy\n",
        "aug_train_acc = modelAug.evaluate(x_train.astype(np.float32), y_train.astype(np.float32), batch_size=batch)\n",
        "print(aug_train_acc)\n",
        "\n",
        "# evalutating test set accuracy\n",
        "aug_test_acc = modelAug.evaluate(x_test.astype(np.float32), y_test.astype(np.float32), batch_size=batch)\n",
        "print(aug_test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tg6n4K8CGtQZ",
        "outputId": "ee43429a-09b6-4657-9f1e-72a6ce0d8e48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "391/391 [==============================] - 884s 2s/step - loss: 2.1526 - sparse_categorical_accuracy: 0.3215 - val_loss: 1.4167 - val_sparse_categorical_accuracy: 0.5144\n",
            "Epoch 2/10\n",
            "391/391 [==============================] - 835s 2s/step - loss: 1.5067 - sparse_categorical_accuracy: 0.4667 - val_loss: 1.2394 - val_sparse_categorical_accuracy: 0.5875\n",
            "Epoch 3/10\n",
            "391/391 [==============================] - 833s 2s/step - loss: 1.2492 - sparse_categorical_accuracy: 0.5573 - val_loss: 1.0584 - val_sparse_categorical_accuracy: 0.6359\n",
            "Epoch 4/10\n",
            "391/391 [==============================] - 838s 2s/step - loss: 1.1227 - sparse_categorical_accuracy: 0.6077 - val_loss: 0.9361 - val_sparse_categorical_accuracy: 0.6768\n",
            "Epoch 5/10\n",
            "391/391 [==============================] - 812s 2s/step - loss: 1.0384 - sparse_categorical_accuracy: 0.6381 - val_loss: 0.9882 - val_sparse_categorical_accuracy: 0.6710\n",
            "Epoch 6/10\n",
            "391/391 [==============================] - 816s 2s/step - loss: 0.9732 - sparse_categorical_accuracy: 0.6644 - val_loss: 0.8046 - val_sparse_categorical_accuracy: 0.7305\n",
            "Epoch 7/10\n",
            "391/391 [==============================] - 804s 2s/step - loss: 0.9262 - sparse_categorical_accuracy: 0.6816 - val_loss: 0.7743 - val_sparse_categorical_accuracy: 0.7414\n",
            "Epoch 8/10\n",
            "391/391 [==============================] - 804s 2s/step - loss: 0.8889 - sparse_categorical_accuracy: 0.6953 - val_loss: 0.7530 - val_sparse_categorical_accuracy: 0.7454\n",
            "Epoch 9/10\n",
            "391/391 [==============================] - 798s 2s/step - loss: 0.8530 - sparse_categorical_accuracy: 0.7054 - val_loss: 0.7008 - val_sparse_categorical_accuracy: 0.7658\n",
            "Epoch 10/10\n",
            "391/391 [==============================] - 793s 2s/step - loss: 0.8228 - sparse_categorical_accuracy: 0.7182 - val_loss: 0.6956 - val_sparse_categorical_accuracy: 0.7687\n",
            "391/391 [==============================] - 143s 367ms/step - loss: 0.5930 - sparse_categorical_accuracy: 0.7939\n",
            "[0.5929514169692993, 0.7938799858093262]\n",
            "79/79 [==============================] - 29s 370ms/step - loss: 0.6956 - sparse_categorical_accuracy: 0.7687\n",
            "[0.695563018321991, 0.7687000036239624]\n",
            "CPU times: user 8h 27min 7s, sys: 6min 31s, total: 8h 33min 39s\n",
            "Wall time: 2h 23min 50s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Results for CPU-based CNN*\n",
        "\n",
        "*   Epochs: 10 epochs at 391 steps per epoch\n",
        "*   Training Set Accuracy: 79.39%\n",
        "*   Test Set Accuracy: 76.87%\n",
        "*   Training Speed: ~820 seconds per Epoch\n",
        "*   Total Time to Run: ~2.5 hours \n",
        "\n"
      ],
      "metadata": {
        "id": "PTsUMwR6jO7w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CNN using GPU**"
      ],
      "metadata": {
        "id": "5wSBtUNP6aSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# runtime was changed to GPU before running the below cells\n",
        "\n",
        "modelAugGPU = create_model() # creating model to train on augmented data using a GPU\n",
        "\n",
        "# compiling model with adam optimizer and sparse categorical crossentropy/accuracy as our evaluation metrics\n",
        "# using a learning rate of .001 so we can have a 1:1 comparison with the CPU trial above\n",
        "modelAugGPU.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(learning_rate=.001),\n",
        "  loss='sparse_categorical_crossentropy',\n",
        "  metrics=['sparse_categorical_accuracy'])"
      ],
      "metadata": {
        "id": "jXOdKPbxKa4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "batch = 128 # keeping batch size the same to ensure a 1:1 comparison\n",
        "\n",
        "# training model on augmented data using GPU with the same hyperparameters as the CPU model to ensure a 1:1 comparison \n",
        "history_cudnn = modelAugGPU.fit(\n",
        "    dataAug2.flow(x_train, y_train, batch_size=batch),\n",
        "    epochs=10,\n",
        "    steps_per_epoch=391,\n",
        "    validation_data=(x_test.astype(np.float32), y_test.astype(np.float32)),\n",
        "    validation_freq=1,\n",
        "    batch_size=batch\n",
        ")\n",
        "\n",
        "# evaluating training set accuracy\n",
        "augGPU_train_acc = modelAugGPU.evaluate(x_train.astype(np.float32), y_train.astype(np.float32), batch_size=batch)\n",
        "print(augGPU_train_acc)\n",
        "\n",
        "# evalutating test set accuracy\n",
        "augGPU_test_acc = modelAugGPU.evaluate(x_test.astype(np.float32), y_test.astype(np.float32), batch_size=batch)\n",
        "print(augGPU_test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "194105cb-a59f-46a7-e69b-0b3e1d53e0d8",
        "id": "gBTnd5ECKa4Z"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "391/391 [==============================] - 35s 66ms/step - loss: 2.1159 - sparse_categorical_accuracy: 0.3319 - val_loss: 1.4195 - val_sparse_categorical_accuracy: 0.4926\n",
            "Epoch 2/10\n",
            "391/391 [==============================] - 25s 65ms/step - loss: 1.5170 - sparse_categorical_accuracy: 0.4677 - val_loss: 1.1366 - val_sparse_categorical_accuracy: 0.6083\n",
            "Epoch 3/10\n",
            "391/391 [==============================] - 25s 64ms/step - loss: 1.2596 - sparse_categorical_accuracy: 0.5529 - val_loss: 1.0419 - val_sparse_categorical_accuracy: 0.6388\n",
            "Epoch 4/10\n",
            "391/391 [==============================] - 25s 64ms/step - loss: 1.1315 - sparse_categorical_accuracy: 0.6047 - val_loss: 0.9046 - val_sparse_categorical_accuracy: 0.6857\n",
            "Epoch 5/10\n",
            "391/391 [==============================] - 25s 63ms/step - loss: 1.0455 - sparse_categorical_accuracy: 0.6374 - val_loss: 0.9784 - val_sparse_categorical_accuracy: 0.6747\n",
            "Epoch 6/10\n",
            "391/391 [==============================] - 25s 64ms/step - loss: 0.9689 - sparse_categorical_accuracy: 0.6630 - val_loss: 0.8037 - val_sparse_categorical_accuracy: 0.7237\n",
            "Epoch 7/10\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 0.9243 - sparse_categorical_accuracy: 0.6827 - val_loss: 0.7686 - val_sparse_categorical_accuracy: 0.7405\n",
            "Epoch 8/10\n",
            "391/391 [==============================] - 25s 63ms/step - loss: 0.8834 - sparse_categorical_accuracy: 0.6971 - val_loss: 0.8496 - val_sparse_categorical_accuracy: 0.7241\n",
            "Epoch 9/10\n",
            "391/391 [==============================] - 24s 62ms/step - loss: 0.8626 - sparse_categorical_accuracy: 0.7067 - val_loss: 0.7744 - val_sparse_categorical_accuracy: 0.7491\n",
            "Epoch 10/10\n",
            "391/391 [==============================] - 25s 63ms/step - loss: 0.8204 - sparse_categorical_accuracy: 0.7197 - val_loss: 0.7024 - val_sparse_categorical_accuracy: 0.7625\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.5879 - sparse_categorical_accuracy: 0.7987\n",
            "[0.5878597497940063, 0.798740029335022]\n",
            "79/79 [==============================] - 1s 11ms/step - loss: 0.7024 - sparse_categorical_accuracy: 0.7625\n",
            "[0.7024380564689636, 0.762499988079071]\n",
            "CPU times: user 5min 33s, sys: 10.3 s, total: 5min 43s\n",
            "Wall time: 4min 25s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Results for GPU-based CNN*\n",
        "\n",
        "\n",
        "\n",
        "*   Epochs: 10 epochs at 391 steps per epoch\n",
        "*   Training Set Accuracy: 79.87%\n",
        "*   Test Set Accuracy: 76.25%\n",
        "*   Training Speed: ~25 seconds per Epoch\n",
        "*   Total Time to Run: ~4.5 minutes\n",
        "\n",
        "The time difference between CPU and GPU is crazy - GPU's give you the freedom to expirement with so much more"
      ],
      "metadata": {
        "id": "OVgKdDZ1NlBR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Taking advantage of the GPU speed to train with several more epochs to maximize accuracy**"
      ],
      "metadata": {
        "id": "-iUPTQOZOCGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelAugGPU = create_model() # creating model to train on augmented data using a GPU\n",
        "\n",
        "# compiling model with adam optimizer and sparse categorical crossentropy/accuracy as our evaluation metrics\n",
        "modelAugGPU.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(learning_rate=.0001), # decreasing learning rate from .001 to .0001 seemed to improve performance\n",
        "  loss='sparse_categorical_crossentropy',\n",
        "  metrics=['sparse_categorical_accuracy'])"
      ],
      "metadata": {
        "id": "cG-3AKGOOFDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(x_train)/128) # this will be my steps per epoch (rounded up)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xfea-C90uik6",
        "outputId": "8ae8e979-d7d5-469b-f197-21ed6a8b635e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "390.625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "batch = 128\n",
        "\n",
        "# training model on augmented data with a batch size of 128, 100 epochs, and 391 steps per epoch\n",
        "# i tried to keep the majority of my hyperparameters the same - only the learning rate and # of epochs were changed\n",
        "historyAugGPU = modelAugGPU.fit(\n",
        "    dataAug2.flow(x_train, y_train, batch_size=batch),\n",
        "    epochs=100,\n",
        "    steps_per_epoch=391,\n",
        "    validation_data=(x_test.astype(np.float32), y_test.astype(np.float32)),\n",
        "    validation_freq=1,\n",
        "    batch_size=batch\n",
        ")\n",
        "\n",
        "# evaluating training set accuracy\n",
        "augGPU_train_acc = modelAugGPU.evaluate(x_train.astype(np.float32), y_train.astype(np.float32), batch_size=batch)\n",
        "print(augGPU_train_acc)\n",
        "\n",
        "# evalutating test set accuracy\n",
        "augGPU_test_acc = modelAugGPU.evaluate(x_test.astype(np.float32), y_test.astype(np.float32), batch_size=batch)\n",
        "print(augGPU_test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04b51108-cf92-4a9e-d4d3-7624ad15ad4a",
        "id": "t8LRlvz3OFDl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "391/391 [==============================] - 34s 62ms/step - loss: 1.9879 - sparse_categorical_accuracy: 0.3331 - val_loss: 3.1114 - val_sparse_categorical_accuracy: 0.2419\n",
            "Epoch 2/100\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 1.6807 - sparse_categorical_accuracy: 0.4244 - val_loss: 1.9954 - val_sparse_categorical_accuracy: 0.4244\n",
            "Epoch 3/100\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 1.5532 - sparse_categorical_accuracy: 0.4641 - val_loss: 1.7351 - val_sparse_categorical_accuracy: 0.4846\n",
            "Epoch 4/100\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 1.4445 - sparse_categorical_accuracy: 0.4988 - val_loss: 1.7276 - val_sparse_categorical_accuracy: 0.4984\n",
            "Epoch 5/100\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 1.3668 - sparse_categorical_accuracy: 0.5238 - val_loss: 1.3549 - val_sparse_categorical_accuracy: 0.5663\n",
            "Epoch 6/100\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 1.3060 - sparse_categorical_accuracy: 0.5431 - val_loss: 1.3317 - val_sparse_categorical_accuracy: 0.5735\n",
            "Epoch 7/100\n",
            "391/391 [==============================] - 24s 60ms/step - loss: 1.2430 - sparse_categorical_accuracy: 0.5639 - val_loss: 1.3706 - val_sparse_categorical_accuracy: 0.5801\n",
            "Epoch 8/100\n",
            "391/391 [==============================] - 24s 60ms/step - loss: 1.1886 - sparse_categorical_accuracy: 0.5840 - val_loss: 1.1059 - val_sparse_categorical_accuracy: 0.6316\n",
            "Epoch 9/100\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 1.1407 - sparse_categorical_accuracy: 0.6007 - val_loss: 1.2926 - val_sparse_categorical_accuracy: 0.6006\n",
            "Epoch 10/100\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 1.1015 - sparse_categorical_accuracy: 0.6125 - val_loss: 1.1177 - val_sparse_categorical_accuracy: 0.6380\n",
            "Epoch 11/100\n",
            "391/391 [==============================] - 24s 62ms/step - loss: 1.0672 - sparse_categorical_accuracy: 0.6255 - val_loss: 1.0360 - val_sparse_categorical_accuracy: 0.6614\n",
            "Epoch 12/100\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 1.0289 - sparse_categorical_accuracy: 0.6364 - val_loss: 0.9498 - val_sparse_categorical_accuracy: 0.6761\n",
            "Epoch 13/100\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 1.0001 - sparse_categorical_accuracy: 0.6478 - val_loss: 1.0640 - val_sparse_categorical_accuracy: 0.6522\n",
            "Epoch 14/100\n",
            "391/391 [==============================] - 24s 60ms/step - loss: 0.9711 - sparse_categorical_accuracy: 0.6587 - val_loss: 0.9180 - val_sparse_categorical_accuracy: 0.6884\n",
            "Epoch 15/100\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 0.9409 - sparse_categorical_accuracy: 0.6691 - val_loss: 0.9137 - val_sparse_categorical_accuracy: 0.6963\n",
            "Epoch 16/100\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 0.9168 - sparse_categorical_accuracy: 0.6781 - val_loss: 0.8814 - val_sparse_categorical_accuracy: 0.7077\n",
            "Epoch 17/100\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 0.8924 - sparse_categorical_accuracy: 0.6864 - val_loss: 0.7881 - val_sparse_categorical_accuracy: 0.7347\n",
            "Epoch 18/100\n",
            "391/391 [==============================] - 23s 60ms/step - loss: 0.8661 - sparse_categorical_accuracy: 0.6953 - val_loss: 0.8564 - val_sparse_categorical_accuracy: 0.7122\n",
            "Epoch 19/100\n",
            "391/391 [==============================] - 24s 60ms/step - loss: 0.8508 - sparse_categorical_accuracy: 0.7023 - val_loss: 0.8098 - val_sparse_categorical_accuracy: 0.7322\n",
            "Epoch 20/100\n",
            "391/391 [==============================] - 23s 60ms/step - loss: 0.8284 - sparse_categorical_accuracy: 0.7117 - val_loss: 0.8218 - val_sparse_categorical_accuracy: 0.7300\n",
            "Epoch 21/100\n",
            "391/391 [==============================] - 23s 60ms/step - loss: 0.8082 - sparse_categorical_accuracy: 0.7174 - val_loss: 0.7281 - val_sparse_categorical_accuracy: 0.7527\n",
            "Epoch 22/100\n",
            "391/391 [==============================] - 24s 60ms/step - loss: 0.7845 - sparse_categorical_accuracy: 0.7241 - val_loss: 0.7428 - val_sparse_categorical_accuracy: 0.7496\n",
            "Epoch 23/100\n",
            "391/391 [==============================] - 24s 60ms/step - loss: 0.7783 - sparse_categorical_accuracy: 0.7280 - val_loss: 0.7376 - val_sparse_categorical_accuracy: 0.7527\n",
            "Epoch 24/100\n",
            "391/391 [==============================] - 23s 60ms/step - loss: 0.7511 - sparse_categorical_accuracy: 0.7384 - val_loss: 0.7230 - val_sparse_categorical_accuracy: 0.7613\n",
            "Epoch 25/100\n",
            "391/391 [==============================] - 23s 60ms/step - loss: 0.7418 - sparse_categorical_accuracy: 0.7403 - val_loss: 0.6792 - val_sparse_categorical_accuracy: 0.7745\n",
            "Epoch 26/100\n",
            "391/391 [==============================] - 25s 63ms/step - loss: 0.7251 - sparse_categorical_accuracy: 0.7453 - val_loss: 0.6576 - val_sparse_categorical_accuracy: 0.7759\n",
            "Epoch 27/100\n",
            "391/391 [==============================] - 25s 63ms/step - loss: 0.7112 - sparse_categorical_accuracy: 0.7522 - val_loss: 0.6676 - val_sparse_categorical_accuracy: 0.7820\n",
            "Epoch 28/100\n",
            "391/391 [==============================] - 25s 64ms/step - loss: 0.6995 - sparse_categorical_accuracy: 0.7559 - val_loss: 0.6612 - val_sparse_categorical_accuracy: 0.7767\n",
            "Epoch 29/100\n",
            "391/391 [==============================] - 25s 64ms/step - loss: 0.6852 - sparse_categorical_accuracy: 0.7612 - val_loss: 0.6511 - val_sparse_categorical_accuracy: 0.7866\n",
            "Epoch 30/100\n",
            "391/391 [==============================] - 25s 64ms/step - loss: 0.6761 - sparse_categorical_accuracy: 0.7626 - val_loss: 0.6270 - val_sparse_categorical_accuracy: 0.7945\n",
            "Epoch 31/100\n",
            "391/391 [==============================] - 25s 63ms/step - loss: 0.6581 - sparse_categorical_accuracy: 0.7690 - val_loss: 0.6521 - val_sparse_categorical_accuracy: 0.7848\n",
            "Epoch 32/100\n",
            "391/391 [==============================] - 25s 63ms/step - loss: 0.6466 - sparse_categorical_accuracy: 0.7732 - val_loss: 0.6413 - val_sparse_categorical_accuracy: 0.7883\n",
            "Epoch 33/100\n",
            "391/391 [==============================] - 25s 63ms/step - loss: 0.6340 - sparse_categorical_accuracy: 0.7787 - val_loss: 0.5732 - val_sparse_categorical_accuracy: 0.8075\n",
            "Epoch 34/100\n",
            "391/391 [==============================] - 25s 63ms/step - loss: 0.6260 - sparse_categorical_accuracy: 0.7808 - val_loss: 0.5785 - val_sparse_categorical_accuracy: 0.8064\n",
            "Epoch 35/100\n",
            "391/391 [==============================] - 25s 63ms/step - loss: 0.6175 - sparse_categorical_accuracy: 0.7832 - val_loss: 0.5910 - val_sparse_categorical_accuracy: 0.8021\n",
            "Epoch 36/100\n",
            "391/391 [==============================] - 25s 64ms/step - loss: 0.6025 - sparse_categorical_accuracy: 0.7887 - val_loss: 0.5819 - val_sparse_categorical_accuracy: 0.8064\n",
            "Epoch 37/100\n",
            "391/391 [==============================] - 25s 63ms/step - loss: 0.5949 - sparse_categorical_accuracy: 0.7916 - val_loss: 0.5897 - val_sparse_categorical_accuracy: 0.8017\n",
            "Epoch 38/100\n",
            "391/391 [==============================] - 25s 64ms/step - loss: 0.5849 - sparse_categorical_accuracy: 0.7955 - val_loss: 0.5577 - val_sparse_categorical_accuracy: 0.8147\n",
            "Epoch 39/100\n",
            "391/391 [==============================] - 25s 64ms/step - loss: 0.5824 - sparse_categorical_accuracy: 0.7945 - val_loss: 0.5781 - val_sparse_categorical_accuracy: 0.8081\n",
            "Epoch 40/100\n",
            "391/391 [==============================] - 25s 64ms/step - loss: 0.5690 - sparse_categorical_accuracy: 0.7989 - val_loss: 0.5553 - val_sparse_categorical_accuracy: 0.8168\n",
            "Epoch 41/100\n",
            "391/391 [==============================] - 25s 64ms/step - loss: 0.5643 - sparse_categorical_accuracy: 0.8025 - val_loss: 0.5538 - val_sparse_categorical_accuracy: 0.8143\n",
            "Epoch 42/100\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 0.5502 - sparse_categorical_accuracy: 0.8050 - val_loss: 0.5514 - val_sparse_categorical_accuracy: 0.8193\n",
            "Epoch 43/100\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 0.5459 - sparse_categorical_accuracy: 0.8084 - val_loss: 0.5356 - val_sparse_categorical_accuracy: 0.8237\n",
            "Epoch 44/100\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.5432 - sparse_categorical_accuracy: 0.8092 - val_loss: 0.5380 - val_sparse_categorical_accuracy: 0.8185\n",
            "Epoch 45/100\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.5349 - sparse_categorical_accuracy: 0.8103 - val_loss: 0.5154 - val_sparse_categorical_accuracy: 0.8254\n",
            "Epoch 46/100\n",
            "391/391 [==============================] - 23s 60ms/step - loss: 0.5265 - sparse_categorical_accuracy: 0.8149 - val_loss: 0.5514 - val_sparse_categorical_accuracy: 0.8198\n",
            "Epoch 47/100\n",
            "391/391 [==============================] - 24s 62ms/step - loss: 0.5168 - sparse_categorical_accuracy: 0.8184 - val_loss: 0.5563 - val_sparse_categorical_accuracy: 0.8168\n",
            "Epoch 48/100\n",
            "391/391 [==============================] - 24s 60ms/step - loss: 0.5089 - sparse_categorical_accuracy: 0.8216 - val_loss: 0.5152 - val_sparse_categorical_accuracy: 0.8254\n",
            "Epoch 49/100\n",
            "391/391 [==============================] - 23s 60ms/step - loss: 0.5048 - sparse_categorical_accuracy: 0.8212 - val_loss: 0.5154 - val_sparse_categorical_accuracy: 0.8319\n",
            "Epoch 50/100\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.5000 - sparse_categorical_accuracy: 0.8248 - val_loss: 0.5128 - val_sparse_categorical_accuracy: 0.8305\n",
            "Epoch 51/100\n",
            "391/391 [==============================] - 23s 60ms/step - loss: 0.4910 - sparse_categorical_accuracy: 0.8286 - val_loss: 0.4850 - val_sparse_categorical_accuracy: 0.8408\n",
            "Epoch 52/100\n",
            "391/391 [==============================] - 23s 60ms/step - loss: 0.4860 - sparse_categorical_accuracy: 0.8302 - val_loss: 0.5045 - val_sparse_categorical_accuracy: 0.8348\n",
            "Epoch 53/100\n",
            "391/391 [==============================] - 23s 60ms/step - loss: 0.4817 - sparse_categorical_accuracy: 0.8304 - val_loss: 0.4833 - val_sparse_categorical_accuracy: 0.8405\n",
            "Epoch 54/100\n",
            "391/391 [==============================] - 23s 60ms/step - loss: 0.4774 - sparse_categorical_accuracy: 0.8315 - val_loss: 0.4582 - val_sparse_categorical_accuracy: 0.8490\n",
            "Epoch 55/100\n",
            "391/391 [==============================] - 23s 60ms/step - loss: 0.4688 - sparse_categorical_accuracy: 0.8351 - val_loss: 0.5065 - val_sparse_categorical_accuracy: 0.8363\n",
            "Epoch 56/100\n",
            "391/391 [==============================] - 24s 61ms/step - loss: 0.4626 - sparse_categorical_accuracy: 0.8377 - val_loss: 0.5145 - val_sparse_categorical_accuracy: 0.8333\n",
            "Epoch 57/100\n",
            "391/391 [==============================] - 24s 60ms/step - loss: 0.4565 - sparse_categorical_accuracy: 0.8405 - val_loss: 0.4994 - val_sparse_categorical_accuracy: 0.8353\n",
            "Epoch 58/100\n",
            "391/391 [==============================] - 23s 60ms/step - loss: 0.4593 - sparse_categorical_accuracy: 0.8384 - val_loss: 0.5364 - val_sparse_categorical_accuracy: 0.8304\n",
            "Epoch 59/100\n",
            "391/391 [==============================] - 23s 60ms/step - loss: 0.4478 - sparse_categorical_accuracy: 0.8436 - val_loss: 0.5018 - val_sparse_categorical_accuracy: 0.8327\n",
            "Epoch 60/100\n",
            "391/391 [==============================] - 24s 60ms/step - loss: 0.4462 - sparse_categorical_accuracy: 0.8441 - val_loss: 0.5269 - val_sparse_categorical_accuracy: 0.8298\n",
            "Epoch 61/100\n",
            "391/391 [==============================] - 23s 60ms/step - loss: 0.4423 - sparse_categorical_accuracy: 0.8434 - val_loss: 0.4775 - val_sparse_categorical_accuracy: 0.8451\n",
            "Epoch 62/100\n",
            "391/391 [==============================] - 23s 60ms/step - loss: 0.4333 - sparse_categorical_accuracy: 0.8457 - val_loss: 0.4758 - val_sparse_categorical_accuracy: 0.8462\n",
            "Epoch 63/100\n",
            "391/391 [==============================] - 24s 60ms/step - loss: 0.4259 - sparse_categorical_accuracy: 0.8497 - val_loss: 0.4695 - val_sparse_categorical_accuracy: 0.8485\n",
            "Epoch 64/100\n",
            "391/391 [==============================] - 23s 60ms/step - loss: 0.4254 - sparse_categorical_accuracy: 0.8502 - val_loss: 0.4848 - val_sparse_categorical_accuracy: 0.8445\n",
            "Epoch 65/100\n",
            "391/391 [==============================] - 23s 60ms/step - loss: 0.4136 - sparse_categorical_accuracy: 0.8530 - val_loss: 0.4608 - val_sparse_categorical_accuracy: 0.8498\n",
            "Epoch 66/100\n",
            "391/391 [==============================] - 24s 60ms/step - loss: 0.4158 - sparse_categorical_accuracy: 0.8529 - val_loss: 0.5109 - val_sparse_categorical_accuracy: 0.8371\n",
            "Epoch 67/100\n",
            "391/391 [==============================] - 24s 60ms/step - loss: 0.4126 - sparse_categorical_accuracy: 0.8533 - val_loss: 0.4852 - val_sparse_categorical_accuracy: 0.8459\n",
            "Epoch 68/100\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.4079 - sparse_categorical_accuracy: 0.8552 - val_loss: 0.4493 - val_sparse_categorical_accuracy: 0.8563\n",
            "Epoch 69/100\n",
            "391/391 [==============================] - 24s 60ms/step - loss: 0.4050 - sparse_categorical_accuracy: 0.8560 - val_loss: 0.4691 - val_sparse_categorical_accuracy: 0.8480\n",
            "Epoch 70/100\n",
            "391/391 [==============================] - 23s 60ms/step - loss: 0.3963 - sparse_categorical_accuracy: 0.8594 - val_loss: 0.4562 - val_sparse_categorical_accuracy: 0.8508\n",
            "Epoch 71/100\n",
            "391/391 [==============================] - 23s 60ms/step - loss: 0.4000 - sparse_categorical_accuracy: 0.8578 - val_loss: 0.4545 - val_sparse_categorical_accuracy: 0.8501\n",
            "Epoch 72/100\n",
            "391/391 [==============================] - 23s 60ms/step - loss: 0.3890 - sparse_categorical_accuracy: 0.8640 - val_loss: 0.4392 - val_sparse_categorical_accuracy: 0.8555\n",
            "Epoch 73/100\n",
            "391/391 [==============================] - 23s 60ms/step - loss: 0.3891 - sparse_categorical_accuracy: 0.8617 - val_loss: 0.4630 - val_sparse_categorical_accuracy: 0.8539\n",
            "Epoch 74/100\n",
            "391/391 [==============================] - 23s 60ms/step - loss: 0.3897 - sparse_categorical_accuracy: 0.8609 - val_loss: 0.4541 - val_sparse_categorical_accuracy: 0.8522\n",
            "Epoch 75/100\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.3777 - sparse_categorical_accuracy: 0.8671 - val_loss: 0.4411 - val_sparse_categorical_accuracy: 0.8588\n",
            "Epoch 76/100\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.3774 - sparse_categorical_accuracy: 0.8654 - val_loss: 0.4960 - val_sparse_categorical_accuracy: 0.8428\n",
            "Epoch 77/100\n",
            "391/391 [==============================] - 23s 60ms/step - loss: 0.3714 - sparse_categorical_accuracy: 0.8688 - val_loss: 0.4651 - val_sparse_categorical_accuracy: 0.8540\n",
            "Epoch 78/100\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.3702 - sparse_categorical_accuracy: 0.8686 - val_loss: 0.4628 - val_sparse_categorical_accuracy: 0.8550\n",
            "Epoch 79/100\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.3732 - sparse_categorical_accuracy: 0.8679 - val_loss: 0.4384 - val_sparse_categorical_accuracy: 0.8594\n",
            "Epoch 80/100\n",
            "391/391 [==============================] - 23s 60ms/step - loss: 0.3679 - sparse_categorical_accuracy: 0.8697 - val_loss: 0.4270 - val_sparse_categorical_accuracy: 0.8662\n",
            "Epoch 81/100\n",
            "391/391 [==============================] - 23s 60ms/step - loss: 0.3575 - sparse_categorical_accuracy: 0.8736 - val_loss: 0.4322 - val_sparse_categorical_accuracy: 0.8619\n",
            "Epoch 82/100\n",
            "391/391 [==============================] - 23s 60ms/step - loss: 0.3614 - sparse_categorical_accuracy: 0.8730 - val_loss: 0.4438 - val_sparse_categorical_accuracy: 0.8594\n",
            "Epoch 83/100\n",
            "391/391 [==============================] - 24s 60ms/step - loss: 0.3525 - sparse_categorical_accuracy: 0.8772 - val_loss: 0.4500 - val_sparse_categorical_accuracy: 0.8569\n",
            "Epoch 84/100\n",
            "391/391 [==============================] - 23s 60ms/step - loss: 0.3532 - sparse_categorical_accuracy: 0.8758 - val_loss: 0.4522 - val_sparse_categorical_accuracy: 0.8561\n",
            "Epoch 85/100\n",
            "391/391 [==============================] - 23s 60ms/step - loss: 0.3465 - sparse_categorical_accuracy: 0.8762 - val_loss: 0.4517 - val_sparse_categorical_accuracy: 0.8598\n",
            "Epoch 86/100\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.3473 - sparse_categorical_accuracy: 0.8766 - val_loss: 0.4276 - val_sparse_categorical_accuracy: 0.8624\n",
            "Epoch 87/100\n",
            "391/391 [==============================] - 23s 60ms/step - loss: 0.3465 - sparse_categorical_accuracy: 0.8776 - val_loss: 0.4494 - val_sparse_categorical_accuracy: 0.8568\n",
            "Epoch 88/100\n",
            "391/391 [==============================] - 23s 60ms/step - loss: 0.3400 - sparse_categorical_accuracy: 0.8787 - val_loss: 0.4814 - val_sparse_categorical_accuracy: 0.8531\n",
            "Epoch 89/100\n",
            "391/391 [==============================] - 23s 60ms/step - loss: 0.3365 - sparse_categorical_accuracy: 0.8811 - val_loss: 0.4404 - val_sparse_categorical_accuracy: 0.8616\n",
            "Epoch 90/100\n",
            "391/391 [==============================] - 23s 60ms/step - loss: 0.3325 - sparse_categorical_accuracy: 0.8821 - val_loss: 0.4453 - val_sparse_categorical_accuracy: 0.8629\n",
            "Epoch 91/100\n",
            "391/391 [==============================] - 23s 60ms/step - loss: 0.3343 - sparse_categorical_accuracy: 0.8818 - val_loss: 0.4164 - val_sparse_categorical_accuracy: 0.8683\n",
            "Epoch 92/100\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.3316 - sparse_categorical_accuracy: 0.8818 - val_loss: 0.4651 - val_sparse_categorical_accuracy: 0.8563\n",
            "Epoch 93/100\n",
            "391/391 [==============================] - 23s 60ms/step - loss: 0.3317 - sparse_categorical_accuracy: 0.8818 - val_loss: 0.4409 - val_sparse_categorical_accuracy: 0.8639\n",
            "Epoch 94/100\n",
            "391/391 [==============================] - 23s 60ms/step - loss: 0.3251 - sparse_categorical_accuracy: 0.8844 - val_loss: 0.4408 - val_sparse_categorical_accuracy: 0.8635\n",
            "Epoch 95/100\n",
            "391/391 [==============================] - 23s 60ms/step - loss: 0.3220 - sparse_categorical_accuracy: 0.8866 - val_loss: 0.4409 - val_sparse_categorical_accuracy: 0.8638\n",
            "Epoch 96/100\n",
            "391/391 [==============================] - 23s 60ms/step - loss: 0.3215 - sparse_categorical_accuracy: 0.8848 - val_loss: 0.4534 - val_sparse_categorical_accuracy: 0.8586\n",
            "Epoch 97/100\n",
            "391/391 [==============================] - 23s 60ms/step - loss: 0.3173 - sparse_categorical_accuracy: 0.8856 - val_loss: 0.4376 - val_sparse_categorical_accuracy: 0.8618\n",
            "Epoch 98/100\n",
            "391/391 [==============================] - 24s 60ms/step - loss: 0.3158 - sparse_categorical_accuracy: 0.8886 - val_loss: 0.4288 - val_sparse_categorical_accuracy: 0.8663\n",
            "Epoch 99/100\n",
            "391/391 [==============================] - 23s 59ms/step - loss: 0.3146 - sparse_categorical_accuracy: 0.8891 - val_loss: 0.4543 - val_sparse_categorical_accuracy: 0.8626\n",
            "Epoch 100/100\n",
            "391/391 [==============================] - 23s 60ms/step - loss: 0.3104 - sparse_categorical_accuracy: 0.8908 - val_loss: 0.4612 - val_sparse_categorical_accuracy: 0.8605\n",
            "391/391 [==============================] - 4s 11ms/step - loss: 0.1300 - sparse_categorical_accuracy: 0.9572\n",
            "[0.13001972436904907, 0.9571999907493591]\n",
            "79/79 [==============================] - 1s 11ms/step - loss: 0.4612 - sparse_categorical_accuracy: 0.8605\n",
            "[0.46121981739997864, 0.8604999780654907]\n",
            "CPU times: user 52min 24s, sys: 1min 23s, total: 53min 47s\n",
            "Wall time: 39min 50s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*GPU-based CNN on Augmented Data Results w/ Smaller Learning Rate and More Epochs*\n",
        "\n",
        "*   Epochs: 100 epochs at 391 steps per epoch\n",
        "*   Training Set Accuracy: 95.72%\n",
        "*   Test Set Accuracy: 86.05%\n",
        "*   Training Speed: ~23 seconds per Epoch\n",
        "*   Total Time to Run: ~40 minutes"
      ],
      "metadata": {
        "id": "_a8ifF2HjVTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting function taken from Moritz Hambach's notebook\n",
        "def plothist(hist):\n",
        "    plt.plot(hist.history['sparse_categorical_accuracy'])\n",
        "    plt.plot(hist.history['val_sparse_categorical_accuracy'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "plothist(historyAugGPU)"
      ],
      "metadata": {
        "id": "rVcULvgCK4Kr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "afb8a2e8-9435-4873-8fbb-af3ba72717bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPUs really allow for a lot more intensive models which is awesome"
      ],
      "metadata": {
        "id": "RA28pYe4QVDi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now let's try out an LSTM model**"
      ],
      "metadata": {
        "id": "e5y22o1ZBShB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape) # just printing this to show the effect of the reshape below\n",
        "x_train_flat = x_train.reshape(50000, 32, -1) # reshaping training set images to be 2D instead of 3D\n",
        "print(x_train_flat.shape) # just printing this to show the effect of the reshape\n",
        "\n",
        "print(x_test.shape) # just printing this to show the effect of the reshape below\n",
        "x_test_flat = x_test.reshape(10000, 32, -1) # reshaping test set images to be 2D instead of 3D\n",
        "print(x_test_flat.shape) # just printing this to show the effect of the reshape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-v6A9ddIJnD",
        "outputId": "6f951693-a5e3-4652-cb07-a74e19cbf2db"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(50000, 32, 96)\n",
            "(10000, 32, 32, 3)\n",
            "(10000, 32, 96)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the Image Data Generator didn't seem to work well with the LSTM model \n",
        "# as such, I'm defining a new augmentation model here which will be applied to our reshaped data\n",
        "dataAug = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.RandomFlip(),\n",
        "    tf.keras.layers.RandomRotation((.1, .3))\n",
        "])\n",
        "\n",
        "x_train_flat_aug = dataAug(x_train_flat) # creating a set of augmented images"
      ],
      "metadata": {
        "id": "6RcXAwtg2mGp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this cell is unecessary - I used it for easy copy and paste into my LSTM models below\n",
        "# it simply contains code from the past two cells consolidated into one\n",
        "x_train_flat = x_train.reshape(50000, 32, -1)\n",
        "x_test_flat = x_test.reshape(10000, 32, -1)\n",
        "\n",
        "dataAug = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.RandomFlip(),\n",
        "    tf.keras.layers.RandomRotation((.1, .3))\n",
        "])\n",
        "\n",
        "x_train_flat_aug = dataAug(x_train_flat)"
      ],
      "metadata": {
        "id": "5aj2UKVpNdMP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LSTM on CPU w/ CUDNN**"
      ],
      "metadata": {
        "id": "eU0BuMJhY6GU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code to create the LSTM model taken from Dr Y's LSTM notebook\n",
        "\n",
        "batch_size = 256 # using batch size of 256 because it had better performance that batch size of 128\n",
        "input_dim = 32   # CIFAR images are 32x32 - I ended up hardcoding the input shape because I had issues with this variable\n",
        "\n",
        "units = 256       # using 256 units as mentioned in Task 2\n",
        "output_size = 10  # CIFAR labels are from 0 to 9 (10 total)\n",
        "\n",
        "# defining function to build the LSTM model w/ parameter that defaults to using CuDNN kernel but gives option to turn off\n",
        "def build_lstm_model(allow_cudnn_kernel=True):\n",
        "  # CuDNN is only available at the layer level, and not at the cell level.\n",
        "  # This means `LSTM(units)` will use the CuDNN kernel,\n",
        "  # while RNN(LSTMCell(units)) will run on non-CuDNN kernel.\n",
        "  if allow_cudnn_kernel:\n",
        "    # Defining the LSTM layer (using CuDNN kernel)\n",
        "    lstm_layer = tf.keras.layers.LSTM(units, input_shape=(x_train_flat.shape[1:])) # return_sequence=True caused issues so I removed it\n",
        "  else:\n",
        "    # Defining the LSTM layer (not using CuDNN kernel)\n",
        "    lstm_layer = tf.keras.layers.RNN(\n",
        "        tf.keras.layers.LSTMCell(units),\n",
        "        input_shape=(x_train_flat.shape[1:]))\n",
        "  # here we are defining the model using the lstm layer defined above\n",
        "  model = tf.keras.models.Sequential([\n",
        "      lstm_layer,\n",
        "      tf.keras.layers.BatchNormalization(), # normalizing the inputs\n",
        "      tf.keras.layers.Dense(256), # adding a layer of 256 densely connected nodes - this seemed to improve performance\n",
        "      tf.keras.layers.Activation('elu'), # using an elu activation function to remain consistent with CNN model\n",
        "      tf.keras.layers.Dropout(.25), # setting random weights to zero to prevent overfitting\n",
        "      tf.keras.layers.Dense(output_size, activation='softmax')] # using output size = 10 since we have that many classes\n",
        "  )\n",
        "  return model"
      ],
      "metadata": {
        "id": "qQ3NFA22CS9b"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model = build_lstm_model(allow_cudnn_kernel=True) # building the model with the CuDNN kernel\n",
        "\n",
        "# compiling the model with sparse categorical crossentropy/accuracy as our metrics\n",
        "# a smaller learning rate performed better in the LSTM model\n",
        "lstm_model.compile(loss='sparse_categorical_crossentropy', \n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=.0001),\n",
        "              metrics=['sparse_categorical_accuracy'])"
      ],
      "metadata": {
        "id": "X1tQqrSECmcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# fitting the model using the augmented data\n",
        "lstm_model.fit(x_train_flat_aug, y_train.astype(np.float32),\n",
        "          validation_data=(x_test_flat.astype(np.float32), y_test.astype(np.float32)),\n",
        "          batch_size=batch_size, \n",
        "          epochs=10)\n",
        "\n",
        "lstm_model.evaluate(x_test_flat, y_test) # evaluating our performance using the test set"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FE6e3qe0C0rg",
        "outputId": "85fee257-fe70-4f80-d4c8-f3bec5ad4573"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "196/196 [==============================] - 66s 321ms/step - loss: 2.3556 - sparse_categorical_accuracy: 0.1979 - val_loss: 2.0383 - val_sparse_categorical_accuracy: 0.2599\n",
            "Epoch 2/10\n",
            "196/196 [==============================] - 58s 298ms/step - loss: 2.0811 - sparse_categorical_accuracy: 0.2614 - val_loss: 1.9365 - val_sparse_categorical_accuracy: 0.2975\n",
            "Epoch 3/10\n",
            "196/196 [==============================] - 60s 307ms/step - loss: 1.9705 - sparse_categorical_accuracy: 0.2929 - val_loss: 1.8932 - val_sparse_categorical_accuracy: 0.3075\n",
            "Epoch 4/10\n",
            "196/196 [==============================] - 59s 303ms/step - loss: 1.9154 - sparse_categorical_accuracy: 0.3101 - val_loss: 1.8702 - val_sparse_categorical_accuracy: 0.3283\n",
            "Epoch 5/10\n",
            "196/196 [==============================] - 57s 290ms/step - loss: 1.8853 - sparse_categorical_accuracy: 0.3192 - val_loss: 1.8443 - val_sparse_categorical_accuracy: 0.3313\n",
            "Epoch 6/10\n",
            "196/196 [==============================] - 57s 291ms/step - loss: 1.8378 - sparse_categorical_accuracy: 0.3333 - val_loss: 1.8222 - val_sparse_categorical_accuracy: 0.3368\n",
            "Epoch 7/10\n",
            "196/196 [==============================] - 57s 290ms/step - loss: 1.8163 - sparse_categorical_accuracy: 0.3434 - val_loss: 1.7986 - val_sparse_categorical_accuracy: 0.3439\n",
            "Epoch 8/10\n",
            "196/196 [==============================] - 56s 287ms/step - loss: 1.7882 - sparse_categorical_accuracy: 0.3500 - val_loss: 1.7610 - val_sparse_categorical_accuracy: 0.3638\n",
            "Epoch 9/10\n",
            "196/196 [==============================] - 56s 288ms/step - loss: 1.7608 - sparse_categorical_accuracy: 0.3623 - val_loss: 1.7800 - val_sparse_categorical_accuracy: 0.3536\n",
            "Epoch 10/10\n",
            "196/196 [==============================] - 56s 288ms/step - loss: 1.7562 - sparse_categorical_accuracy: 0.3615 - val_loss: 1.7545 - val_sparse_categorical_accuracy: 0.3667\n",
            "313/313 [==============================] - 11s 30ms/step - loss: 1.7545 - sparse_categorical_accuracy: 0.3667\n",
            "CPU times: user 27min 6s, sys: 1min 43s, total: 28min 49s\n",
            "Wall time: 9min 54s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.7544924020767212, 0.3666999936103821]"
            ]
          },
          "metadata": {},
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Results for CPU w/ CuDNN:*\n",
        "* Time to run w/ CuDNN Kernel: ~1 minute per epoch\n",
        "* Total Time to Run: ~10 minutes\n",
        "* Test Accuracy: 36.67%"
      ],
      "metadata": {
        "id": "-p57ORq15RE1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LSTM on CPU w/o CUDNN** (didn't realize that CuDNN isn't relevant for CPU)"
      ],
      "metadata": {
        "id": "E1H6C75EZDy2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model = build_lstm_model(allow_cudnn_kernel=False) # building the model without a CuDNN kernel\n",
        "\n",
        "# compiling the model with sparse categorical crossentropy/accuracy as our metrics\n",
        "# a smaller learning rate performed better in the LSTM model\n",
        "lstm_model.compile(loss='sparse_categorical_crossentropy', \n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=.0001),\n",
        "              metrics=['sparse_categorical_accuracy'])"
      ],
      "metadata": {
        "id": "A2o7R2Mvz7_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# fitting the model with the augmented data\n",
        "lstm_model.fit(x_train_flat_aug, y_train.astype(np.float32),\n",
        "          validation_data=(x_test_flat.astype(np.float32), y_test.astype(np.float32)),\n",
        "          batch_size=batch_size, \n",
        "          epochs=10)\n",
        "\n",
        "lstm_model.evaluate(x_test_flat, y_test) # evaluating model using the test set"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c12dcd12-7e6c-4a43-b50e-2a218d844159",
        "id": "PH8_tUB7z7_9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "196/196 [==============================] - 58s 287ms/step - loss: 2.3313 - sparse_categorical_accuracy: 0.2091 - val_loss: 2.0294 - val_sparse_categorical_accuracy: 0.2630\n",
            "Epoch 2/10\n",
            "196/196 [==============================] - 58s 294ms/step - loss: 2.0773 - sparse_categorical_accuracy: 0.2652 - val_loss: 1.9639 - val_sparse_categorical_accuracy: 0.2902\n",
            "Epoch 3/10\n",
            "196/196 [==============================] - 59s 302ms/step - loss: 1.9839 - sparse_categorical_accuracy: 0.2922 - val_loss: 1.9039 - val_sparse_categorical_accuracy: 0.3091\n",
            "Epoch 4/10\n",
            "196/196 [==============================] - 58s 294ms/step - loss: 1.9100 - sparse_categorical_accuracy: 0.3132 - val_loss: 1.8363 - val_sparse_categorical_accuracy: 0.3365\n",
            "Epoch 5/10\n",
            "196/196 [==============================] - 56s 286ms/step - loss: 1.8681 - sparse_categorical_accuracy: 0.3291 - val_loss: 1.8105 - val_sparse_categorical_accuracy: 0.3418\n",
            "Epoch 6/10\n",
            "196/196 [==============================] - 58s 294ms/step - loss: 1.8327 - sparse_categorical_accuracy: 0.3363 - val_loss: 1.7918 - val_sparse_categorical_accuracy: 0.3492\n",
            "Epoch 7/10\n",
            "196/196 [==============================] - 57s 291ms/step - loss: 1.8016 - sparse_categorical_accuracy: 0.3493 - val_loss: 1.7710 - val_sparse_categorical_accuracy: 0.3611\n",
            "Epoch 8/10\n",
            "196/196 [==============================] - 57s 292ms/step - loss: 1.7833 - sparse_categorical_accuracy: 0.3543 - val_loss: 1.7709 - val_sparse_categorical_accuracy: 0.3573\n",
            "Epoch 9/10\n",
            "196/196 [==============================] - 58s 295ms/step - loss: 1.7573 - sparse_categorical_accuracy: 0.3666 - val_loss: 1.7466 - val_sparse_categorical_accuracy: 0.3679\n",
            "Epoch 10/10\n",
            "196/196 [==============================] - 57s 292ms/step - loss: 1.7357 - sparse_categorical_accuracy: 0.3684 - val_loss: 1.7357 - val_sparse_categorical_accuracy: 0.3732\n",
            "313/313 [==============================] - 10s 31ms/step - loss: 1.7357 - sparse_categorical_accuracy: 0.3732\n",
            "CPU times: user 27min 12s, sys: 1min 31s, total: 28min 44s\n",
            "Wall time: 10min 33s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.735719084739685, 0.373199999332428]"
            ]
          },
          "metadata": {},
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Results for CPU w/o CuDNN:*\n",
        "* Time to run w/ CuDNN Kernel: ~1 minute per epoch\n",
        "* Total Time to Run: 10.5 minutes\n",
        "* Test Accuracy: 37.32%\n",
        "\n",
        "I now realize that CuDNN is only applicable when running GPU. Oh well"
      ],
      "metadata": {
        "id": "HYCtrMLm5VAz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LSTM on GPU w/ CUDNN**"
      ],
      "metadata": {
        "id": "IRWTD6aGY-XP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model_gpu = build_lstm_model(allow_cudnn_kernel=True) # building the model with the CuDNN kernel\n",
        "\n",
        "# compiling the model with sparse categorical crossentropy/accuracy as our metrics\n",
        "# a smaller learning rate performed better in the LSTM model\n",
        "lstm_model_gpu.compile(loss='sparse_categorical_crossentropy', \n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=.0001),\n",
        "              metrics=['sparse_categorical_accuracy'])"
      ],
      "metadata": {
        "id": "MdMlQk4bcAaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# fitting the model to the augmented dataset\n",
        "lstm_model_gpu.fit(x_train_flat_aug, y_train.astype(np.float32),\n",
        "          validation_data=(x_test_flat.astype(np.float32), y_test.astype(np.float32)),\n",
        "          batch_size=batch_size, \n",
        "          epochs=10)\n",
        "\n",
        "lstm_model_gpu.evaluate(x_test_flat, y_test) # evaluating performance on the test set"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad5cb57d-0321-4330-c024-a7cad5ae91b2",
        "id": "AmEyZWoxcAai"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "196/196 [==============================] - 4s 10ms/step - loss: 2.3042 - sparse_categorical_accuracy: 0.2082 - val_loss: 2.0121 - val_sparse_categorical_accuracy: 0.2662\n",
            "Epoch 2/10\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 2.0507 - sparse_categorical_accuracy: 0.2718 - val_loss: 1.9071 - val_sparse_categorical_accuracy: 0.2973\n",
            "Epoch 3/10\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.9422 - sparse_categorical_accuracy: 0.3009 - val_loss: 1.8615 - val_sparse_categorical_accuracy: 0.3179\n",
            "Epoch 4/10\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.8880 - sparse_categorical_accuracy: 0.3195 - val_loss: 1.8297 - val_sparse_categorical_accuracy: 0.3351\n",
            "Epoch 5/10\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.8339 - sparse_categorical_accuracy: 0.3352 - val_loss: 1.7925 - val_sparse_categorical_accuracy: 0.3491\n",
            "Epoch 6/10\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.8006 - sparse_categorical_accuracy: 0.3435 - val_loss: 1.7765 - val_sparse_categorical_accuracy: 0.3509\n",
            "Epoch 7/10\n",
            "196/196 [==============================] - 1s 8ms/step - loss: 1.7717 - sparse_categorical_accuracy: 0.3536 - val_loss: 1.7703 - val_sparse_categorical_accuracy: 0.3521\n",
            "Epoch 8/10\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.7535 - sparse_categorical_accuracy: 0.3621 - val_loss: 1.7354 - val_sparse_categorical_accuracy: 0.3690\n",
            "Epoch 9/10\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.7356 - sparse_categorical_accuracy: 0.3673 - val_loss: 1.7193 - val_sparse_categorical_accuracy: 0.3802\n",
            "Epoch 10/10\n",
            "196/196 [==============================] - 2s 8ms/step - loss: 1.7116 - sparse_categorical_accuracy: 0.3760 - val_loss: 1.7081 - val_sparse_categorical_accuracy: 0.3706\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.7081 - sparse_categorical_accuracy: 0.3706\n",
            "CPU times: user 26.1 s, sys: 2.47 s, total: 28.6 s\n",
            "Wall time: 18.9 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.7080812454223633, 0.37059998512268066]"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Results for GPU w/ CuDNN:*\n",
        "* Time to run w/ CuDNN Kernel: ~2 seconds per epoch \n",
        "* Total Time to Run: ~20 seconds\n",
        "* Test Accuracy: 37.06%"
      ],
      "metadata": {
        "id": "NVc-f_fEkVlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LSTM on GPU w/o CUDNN**"
      ],
      "metadata": {
        "id": "mQeDAQQwZJ35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model_gpu = build_lstm_model(allow_cudnn_kernel=False) # building model without CuDNN kernel\n",
        "\n",
        "# compiling the model with sparse categorical crossentropy/accuracy as our metrics\n",
        "# a smaller learning rate performed better in the LSTM model\n",
        "lstm_model_gpu.compile(loss='sparse_categorical_crossentropy', \n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=.0001),\n",
        "              metrics=['sparse_categorical_accuracy'])"
      ],
      "metadata": {
        "id": "xES3esJogfyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# fitting the model using augmented dataset\n",
        "lstm_model_gpu.fit(x_train_flat_aug, y_train.astype(np.float32),\n",
        "          validation_data=(x_test_flat.astype(np.float32), y_test.astype(np.float32)),\n",
        "          batch_size=batch_size, \n",
        "          epochs=10)\n",
        "\n",
        "lstm_model_gpu.evaluate(x_test_flat, y_test) # evaluating performance against the test set"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8b74b66-0ce0-41d6-f4b7-62d6e442bfe9",
        "id": "_M6CcC47gfyq"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "196/196 [==============================] - 11s 47ms/step - loss: 2.3277 - sparse_categorical_accuracy: 0.2009 - val_loss: 2.0397 - val_sparse_categorical_accuracy: 0.2634\n",
            "Epoch 2/10\n",
            "196/196 [==============================] - 9s 45ms/step - loss: 2.0717 - sparse_categorical_accuracy: 0.2668 - val_loss: 1.9318 - val_sparse_categorical_accuracy: 0.3023\n",
            "Epoch 3/10\n",
            "196/196 [==============================] - 9s 45ms/step - loss: 1.9696 - sparse_categorical_accuracy: 0.2911 - val_loss: 1.8706 - val_sparse_categorical_accuracy: 0.3216\n",
            "Epoch 4/10\n",
            "196/196 [==============================] - 9s 46ms/step - loss: 1.9133 - sparse_categorical_accuracy: 0.3079 - val_loss: 1.8488 - val_sparse_categorical_accuracy: 0.3350\n",
            "Epoch 5/10\n",
            "196/196 [==============================] - 9s 44ms/step - loss: 1.8548 - sparse_categorical_accuracy: 0.3288 - val_loss: 1.8225 - val_sparse_categorical_accuracy: 0.3354\n",
            "Epoch 6/10\n",
            "196/196 [==============================] - 9s 45ms/step - loss: 1.8276 - sparse_categorical_accuracy: 0.3376 - val_loss: 1.7974 - val_sparse_categorical_accuracy: 0.3525\n",
            "Epoch 7/10\n",
            "196/196 [==============================] - 9s 44ms/step - loss: 1.7988 - sparse_categorical_accuracy: 0.3497 - val_loss: 1.7806 - val_sparse_categorical_accuracy: 0.3558\n",
            "Epoch 8/10\n",
            "196/196 [==============================] - 9s 45ms/step - loss: 1.7705 - sparse_categorical_accuracy: 0.3570 - val_loss: 1.7636 - val_sparse_categorical_accuracy: 0.3618\n",
            "Epoch 9/10\n",
            "196/196 [==============================] - 9s 45ms/step - loss: 1.7473 - sparse_categorical_accuracy: 0.3667 - val_loss: 1.7610 - val_sparse_categorical_accuracy: 0.3622\n",
            "Epoch 10/10\n",
            "196/196 [==============================] - 9s 44ms/step - loss: 1.7287 - sparse_categorical_accuracy: 0.3693 - val_loss: 1.7343 - val_sparse_categorical_accuracy: 0.3719\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 1.7343 - sparse_categorical_accuracy: 0.3719\n",
            "CPU times: user 3min 15s, sys: 29.9 s, total: 3min 45s\n",
            "Wall time: 1min 32s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.73432457447052, 0.3718999922275543]"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Results for GPU w/o CuDNN:*\n",
        "* Time to run w/p CuDNN Kernel: ~9 seconds per epoch\n",
        "* Total time to run w/o CuDNN Kernel: ~1.5 minutes\n",
        "* Test Accuracy: 37.19%\n",
        "\n",
        "Much slower than when using the CuDNN kernel"
      ],
      "metadata": {
        "id": "QJvbW4JvkQGz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YWXVBMr02yp"
      },
      "source": [
        "# Task 3\n",
        "Run the LSTM solution in Task2 on a TPU and report the performance "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  resolver = tf.distribute.cluster_resolver.TPUClusterResolver()  # detecting the TPU\n",
        "  print('Running on TPU', resolver.cluster_spec().as_dict()['worker']) # print statement for debugging\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime') # this exception will be raised if not connected to a TPU runtime\n",
        "tf.config.experimental_connect_to_cluster(resolver) # connecting to the identified cluster\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver) # initializing the TPU \n",
        "strategy = tf.distribute.TPUStrategy(resolver) # defining strategy, the scope of which will allow us to train on the TPU\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU')) # print for debugging and knowledge purposes\n",
        "with strategy.scope(): # this allows the following indented code to be run on the TPU\n",
        "  # loading CIFAR 10 dataset\n",
        "  (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "  # flattening inputs for the LSTM\n",
        "  x_train_flat = x_train.reshape(50000, 32, -1)\n",
        "  x_test_flat = x_test.reshape(10000, 32, -1)\n",
        "  # defining the data augmentation we want to implement\n",
        "  dataAug = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.RandomFlip(),\n",
        "    tf.keras.layers.RandomRotation((.1, .3))\n",
        "  ])\n",
        "  # fitting training set to the data augmentation\n",
        "  x_train_flat_aug = dataAug(x_train_flat)\n",
        "  x_test_flat_aug = dataAug(x_test_flat)\n",
        "  # building the model using the predefined function\n",
        "  model = build_lstm_model(allow_cudnn_kernel=True)\n",
        "  # compiling the model with sparse categorical crossentropy/accuracy as our metrics\n",
        "  # a smaller learning rate performed better in the LSTM model\n",
        "  model.compile(\n",
        "      optimizer=tf.keras.optimizers.Adam(learning_rate=.0001),\n",
        "      loss='sparse_categorical_crossentropy',\n",
        "      metrics=['sparse_categorical_accuracy'])\n",
        "  # fitting the model to the augmented training data\n",
        "  model.fit(x_train_flat_aug, y_train.astype(np.float32),\n",
        "          validation_data=(x_test_flat_aug, y_test.astype(np.float32)),\n",
        "          batch_size=batch_size, \n",
        "          epochs=10,\n",
        "          steps_per_epoch=196)\n",
        "\n",
        "  model.evaluate(x_test_flat, y_test) # evaluating the perfomance of the model on the test set"
      ],
      "metadata": {
        "id": "UFX9InXmME9n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5deb514-c2c9-49d3-95b9-ec04c76cb5d9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on TPU ['10.114.34.250:8470']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.114.34.250:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU')]\n",
            "Epoch 1/10\n",
            "196/196 [==============================] - 14s 42ms/step - loss: 2.2707 - sparse_categorical_accuracy: 0.2065 - val_loss: 2.0250 - val_sparse_categorical_accuracy: 0.2598\n",
            "Epoch 2/10\n",
            "196/196 [==============================] - 5s 26ms/step - loss: 2.0565 - sparse_categorical_accuracy: 0.2649 - val_loss: 1.9394 - val_sparse_categorical_accuracy: 0.2919\n",
            "Epoch 3/10\n",
            "196/196 [==============================] - 5s 26ms/step - loss: 1.9590 - sparse_categorical_accuracy: 0.2922 - val_loss: 1.8894 - val_sparse_categorical_accuracy: 0.3130\n",
            "Epoch 4/10\n",
            "196/196 [==============================] - 5s 26ms/step - loss: 1.9062 - sparse_categorical_accuracy: 0.3082 - val_loss: 1.8615 - val_sparse_categorical_accuracy: 0.3243\n",
            "Epoch 5/10\n",
            "196/196 [==============================] - 5s 25ms/step - loss: 1.8584 - sparse_categorical_accuracy: 0.3221 - val_loss: 1.8323 - val_sparse_categorical_accuracy: 0.3401\n",
            "Epoch 6/10\n",
            "196/196 [==============================] - 5s 26ms/step - loss: 1.8262 - sparse_categorical_accuracy: 0.3379 - val_loss: 1.7936 - val_sparse_categorical_accuracy: 0.3546\n",
            "Epoch 7/10\n",
            "196/196 [==============================] - 5s 27ms/step - loss: 1.7947 - sparse_categorical_accuracy: 0.3486 - val_loss: 1.7842 - val_sparse_categorical_accuracy: 0.3575\n",
            "Epoch 8/10\n",
            "196/196 [==============================] - 6s 29ms/step - loss: 1.7783 - sparse_categorical_accuracy: 0.3537 - val_loss: 1.7709 - val_sparse_categorical_accuracy: 0.3596\n",
            "Epoch 9/10\n",
            "196/196 [==============================] - 5s 26ms/step - loss: 1.7568 - sparse_categorical_accuracy: 0.3613 - val_loss: 1.7630 - val_sparse_categorical_accuracy: 0.3622\n",
            "Epoch 10/10\n",
            "196/196 [==============================] - 5s 27ms/step - loss: 1.7390 - sparse_categorical_accuracy: 0.3664 - val_loss: 1.7351 - val_sparse_categorical_accuracy: 0.3719\n",
            "313/313 [==============================] - 9s 21ms/step - loss: 1.7355 - sparse_categorical_accuracy: 0.3715\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing once more using %%time"
      ],
      "metadata": {
        "id": "4R8Xdnsz6oVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# fitting the model to the augmented training set\n",
        "model.fit(x_train_flat_aug, y_train.astype(np.float32),\n",
        "          validation_data=(x_test_flat_aug, y_test.astype(np.float32)),\n",
        "          batch_size=batch_size, \n",
        "          epochs=10,\n",
        "          steps_per_epoch=196)\n",
        "\n",
        "model.evaluate(x_test_flat, y_test) # evaluating the model against the test set"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFz0geEMTZwn",
        "outputId": "4ca2bceb-4f5b-4956-fc06-863b6cc3d2a8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "196/196 [==============================] - 14s 42ms/step - loss: 2.3153 - sparse_categorical_accuracy: 0.1981 - val_loss: 2.0426 - val_sparse_categorical_accuracy: 0.2716\n",
            "Epoch 2/10\n",
            "196/196 [==============================] - 5s 25ms/step - loss: 2.0571 - sparse_categorical_accuracy: 0.2665 - val_loss: 1.9478 - val_sparse_categorical_accuracy: 0.2969\n",
            "Epoch 3/10\n",
            "196/196 [==============================] - 5s 25ms/step - loss: 1.9633 - sparse_categorical_accuracy: 0.2942 - val_loss: 1.8880 - val_sparse_categorical_accuracy: 0.3157\n",
            "Epoch 4/10\n",
            "196/196 [==============================] - 5s 25ms/step - loss: 1.9071 - sparse_categorical_accuracy: 0.3117 - val_loss: 1.8634 - val_sparse_categorical_accuracy: 0.3307\n",
            "Epoch 5/10\n",
            "196/196 [==============================] - 6s 28ms/step - loss: 1.8718 - sparse_categorical_accuracy: 0.3211 - val_loss: 1.8513 - val_sparse_categorical_accuracy: 0.3323\n",
            "Epoch 6/10\n",
            "196/196 [==============================] - 5s 25ms/step - loss: 1.8354 - sparse_categorical_accuracy: 0.3325 - val_loss: 1.8210 - val_sparse_categorical_accuracy: 0.3399\n",
            "Epoch 7/10\n",
            "196/196 [==============================] - 5s 25ms/step - loss: 1.8096 - sparse_categorical_accuracy: 0.3426 - val_loss: 1.7949 - val_sparse_categorical_accuracy: 0.3531\n",
            "Epoch 8/10\n",
            "196/196 [==============================] - 5s 25ms/step - loss: 1.7932 - sparse_categorical_accuracy: 0.3461 - val_loss: 1.7944 - val_sparse_categorical_accuracy: 0.3537\n",
            "Epoch 9/10\n",
            "196/196 [==============================] - 5s 25ms/step - loss: 1.7794 - sparse_categorical_accuracy: 0.3520 - val_loss: 1.7705 - val_sparse_categorical_accuracy: 0.3643\n",
            "Epoch 10/10\n",
            "196/196 [==============================] - 6s 33ms/step - loss: 1.7572 - sparse_categorical_accuracy: 0.3593 - val_loss: 1.7598 - val_sparse_categorical_accuracy: 0.3605\n",
            "313/313 [==============================] - 8s 19ms/step - loss: 1.7595 - sparse_categorical_accuracy: 0.3612\n",
            "CPU times: user 30.9 s, sys: 4.1 s, total: 35 s\n",
            "Wall time: 1min 9s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.759548544883728, 0.3612000048160553]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Results for TPU:*\n",
        "* Time to run: ~5 seconds per epoch\n",
        "* Total time to run: ~1 minute\n",
        "* Test Accuracy: 36.12%\n",
        "\n",
        "Surprised that the CuDNN GPU model is faster than the TPU - pretty cool to see how fast the CuDNN kernel is on LSTMs"
      ],
      "metadata": {
        "id": "MlIvMrW4TxVk"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "58f68c893d27d44de5f329b5c78da41b4997af8d492e4e8bd7c62547c498f83b"
      }
    },
    "accelerator": "TPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}